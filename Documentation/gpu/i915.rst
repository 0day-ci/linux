===========================
 drm/i915 Intel GFX Driver
===========================

The drm/i915 driver supports all (with the exception of some very early
models) integrated GFX chipsets with both Intel display and rendering
blocks. This excludes a set of SoC platforms with an SGX rendering unit,
those have basic support through the gma500 drm driver.

Core Driver Infrastructure
==========================

This section covers core driver infrastructure used by both the display
and the GEM parts of the driver.

Runtime Power Management
------------------------

.. kernel-doc:: drivers/gpu/drm/i915/intel_runtime_pm.c
   :doc: runtime pm

.. kernel-doc:: drivers/gpu/drm/i915/intel_runtime_pm.c
   :internal:

.. kernel-doc:: drivers/gpu/drm/i915/intel_uncore.c
   :internal:

Interrupt Handling
------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_irq.c
   :doc: interrupt handling

.. kernel-doc:: drivers/gpu/drm/i915/i915_irq.c
   :functions: intel_irq_init intel_irq_init_hw intel_hpd_init

.. kernel-doc:: drivers/gpu/drm/i915/i915_irq.c
   :functions: intel_runtime_pm_disable_interrupts

.. kernel-doc:: drivers/gpu/drm/i915/i915_irq.c
   :functions: intel_runtime_pm_enable_interrupts

Intel GVT-g Guest Support(vGPU)
-------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_vgpu.c
   :doc: Intel GVT-g guest support

.. kernel-doc:: drivers/gpu/drm/i915/i915_vgpu.c
   :internal:

Intel GVT-g Host Support(vGPU device model)
-------------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/intel_gvt.c
   :doc: Intel GVT-g host support

.. kernel-doc:: drivers/gpu/drm/i915/intel_gvt.c
   :internal:

Workarounds
-----------

.. kernel-doc:: drivers/gpu/drm/i915/gt/intel_workarounds.c
   :doc: Hardware workarounds

Display Hardware Handling
=========================

This section covers everything related to the display hardware including
the mode setting infrastructure, plane, sprite and cursor handling and
display, output probing and related topics.

Mode Setting Infrastructure
---------------------------

The i915 driver is thus far the only DRM driver which doesn't use the
common DRM helper code to implement mode setting sequences. Thus it has
its own tailor-made infrastructure for executing a display configuration
change.

Frontbuffer Tracking
--------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_frontbuffer.c
   :doc: frontbuffer tracking

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_frontbuffer.h
   :internal:

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_frontbuffer.c
   :internal:

Display FIFO Underrun Reporting
-------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_fifo_underrun.c
   :doc: fifo underrun handling

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_fifo_underrun.c
   :internal:

Plane Configuration
-------------------

This section covers plane configuration and composition with the primary
plane, sprites, cursors and overlays. This includes the infrastructure
to do atomic vsync'ed updates of all this state and also tightly coupled
topics like watermark setup and computation, framebuffer compression and
panel self refresh.

Atomic Plane Helpers
--------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_atomic_plane.c
   :doc: atomic plane helpers

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_atomic_plane.c
   :internal:

Asynchronous Page Flip
----------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_display.c
   :doc: asynchronous flip implementation

Output Probing
--------------

This section covers output probing and related infrastructure like the
hotplug interrupt storm detection and mitigation code. Note that the
i915 driver still uses most of the common DRM helper code for output
probing, so those sections fully apply.

Hotplug
-------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_hotplug.c
   :doc: Hotplug

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_hotplug.c
   :internal:

High Definition Audio
---------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_audio.c
   :doc: High Definition Audio over HDMI and Display Port

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_audio.c
   :internal:

.. kernel-doc:: include/drm/i915_component.h
   :internal:

Intel HDMI LPE Audio Support
----------------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_lpe_audio.c
   :doc: LPE Audio integration for HDMI or DP playback

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_lpe_audio.c
   :internal:

Panel Self Refresh PSR (PSR/SRD)
--------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_psr.c
   :doc: Panel Self Refresh (PSR/SRD)

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_psr.c
   :internal:

Frame Buffer Compression (FBC)
------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_fbc.c
   :doc: Frame Buffer Compression (FBC)

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_fbc.c
   :internal:

Display Refresh Rate Switching (DRRS)
-------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :doc: Display Refresh Rate Switching (DRRS)

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_dp_set_drrs_state

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_edp_drrs_enable

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_edp_drrs_disable

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_edp_drrs_invalidate

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_edp_drrs_flush

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dp.c
   :functions: intel_dp_drrs_init

DPIO
----

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dpio_phy.c
   :doc: DPIO

DMC Firmware Support
--------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dmc.c
   :doc: DMC Firmware Support

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dmc.c
   :internal:

Video BIOS Table (VBT)
----------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_bios.c
   :doc: Video BIOS Table (VBT)

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_bios.c
   :internal:

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_vbt_defs.h
   :internal:

Display clocks
--------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_cdclk.c
   :doc: CDCLK / RAWCLK

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_cdclk.c
   :internal:

Display PLLs
------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dpll_mgr.c
   :doc: Display PLLs

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dpll_mgr.c
   :internal:

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dpll_mgr.h
   :internal:

Display State Buffer
--------------------

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dsb.c
   :doc: DSB

.. kernel-doc:: drivers/gpu/drm/i915/display/intel_dsb.c
   :internal:

Memory Management and Command Submission
========================================

This sections covers all things related to the GEM implementation in the
i915 driver.

Intel GPU Basics
----------------

An Intel GPU has multiple engines. There are several engine types.

- RCS engine is for rendering 3D and performing compute, this is named
  `I915_EXEC_RENDER` in user space.
- BCS is a blitting (copy) engine, this is named `I915_EXEC_BLT` in user
  space.
- VCS is a video encode and decode engine, this is named `I915_EXEC_BSD`
  in user space
- VECS is video enhancement engine, this is named `I915_EXEC_VEBOX` in user
  space.
- The enumeration `I915_EXEC_DEFAULT` does not refer to specific engine;
  instead it is to be used by user space to specify a default rendering
  engine (for 3D) that may or may not be the same as RCS.

The Intel GPU family is a family of integrated GPU's using Unified
Memory Access. For having the GPU "do work", user space will feed the
GPU batch buffers via one of the ioctls `DRM_IOCTL_I915_GEM_EXECBUFFER2`
or `DRM_IOCTL_I915_GEM_EXECBUFFER2_WR`. Most such batchbuffers will
instruct the GPU to perform work (for example rendering) and that work
needs memory from which to read and memory to which to write. All memory
is encapsulated within GEM buffer objects (usually created with the ioctl
`DRM_IOCTL_I915_GEM_CREATE`). An ioctl providing a batchbuffer for the GPU
to create will also list all GEM buffer objects that the batchbuffer reads
and/or writes. For implementation details of memory management see
`GEM BO Management Implementation Details`_.

The i915 driver allows user space to create a context via the ioctl
`DRM_IOCTL_I915_GEM_CONTEXT_CREATE` which is identified by a 32-bit
integer. Such a context should be viewed by user-space as -loosely-
analogous to the idea of a CPU process of an operating system. The i915
driver guarantees that commands issued to a fixed context are to be
executed so that writes of a previously issued command are seen by
reads of following commands. Actions issued between different contexts
(even if from the same file descriptor) are NOT given that guarantee
and the only way to synchronize across contexts (even from the same
file descriptor) is through the use of fences. At least as far back as
Gen4, also have that a context carries with it a GPU HW context;
the HW context is essentially (most of atleast) the state of a GPU.
In addition to the ordering guarantees, the kernel will restore GPU
state via HW context when commands are issued to a context, this saves
user space the need to restore (most of atleast) the GPU state at the
start of each batchbuffer. The non-deprecated ioctls to submit batchbuffer
work can pass that ID (in the lower bits of drm_i915_gem_execbuffer2::rsvd1)
to identify what context to use with the command.

The GPU has its own memory management and address space. The kernel
driver maintains the memory translation table for the GPU. For older
GPUs (i.e. those before Gen8), there is a single global such translation
table, a global Graphics Translation Table (GTT). For newer generation
GPUs each context has its own translation table, called Per-Process
Graphics Translation Table (PPGTT). Of important note, is that although
PPGTT is named per-process it is actually per context. When user space
submits a batchbuffer, the kernel walks the list of GEM buffer objects
used by the batchbuffer and guarantees that not only is the memory of
each such GEM buffer object resident but it is also present in the
(PP)GTT. If the GEM buffer object is not yet placed in the (PP)GTT,
then it is given an address. Two consequences of this are: the kernel
needs to edit the batchbuffer submitted to write the correct value of
the GPU address when a GEM BO is assigned a GPU address and the kernel
might evict a different GEM BO from the (PP)GTT to make address room
for another GEM BO. Consequently, the ioctls submitting a batchbuffer
for execution also include a list of all locations within buffers that
refer to GPU-addresses so that the kernel can edit the buffer correctly.
This process is dubbed relocation.

Engine Discovery uAPI
---------------------

Engine discovery uAPI is a way of enumerating physical engines present in a GPU
associated with an open i915 DRM file descriptor. This supersedes the old way of
using `DRM_IOCTL_I915_GETPARAM` and engine identifiers like
`I915_PARAM_HAS_BLT`.

The need for this interface came starting with Icelake and newer GPUs, which
started to establish a pattern of having multiple engines of a same class, where
not all instances were always completely functionally equivalent.

Entry point for this uapi is `DRM_IOCTL_I915_QUERY` with the
`DRM_I915_QUERY_ENGINE_INFO` as the queried item id.

Example for getting the list of engines:

.. code-block:: C

	struct drm_i915_query_engine_info *info;
	struct drm_i915_query_item item = {
		.query_id = DRM_I915_QUERY_ENGINE_INFO;
	};
	struct drm_i915_query query = {
		.num_items = 1,
		.items_ptr = (uintptr_t)&item,
	};
	int err, i;

	// First query the size of the blob we need, this needs to be large
	// enough to hold our array of engines. The kernel will fill out the
	// item.length for us, which is the number of bytes we need.
	//
	// Alternatively a large buffer can be allocated straight away enabling
	// querying in one pass, in which case item.length should contain the
	// length of the provided buffer.
	err = ioctl(fd, DRM_IOCTL_I915_QUERY, &query);
	if (err) ...

	info = calloc(1, item.length);
	// Now that we allocated the required number of bytes, we call the ioctl
	// again, this time with the data_ptr pointing to our newly allocated
	// blob, which the kernel can then populate with info on all engines.
	item.data_ptr = (uintptr_t)&info,

	err = ioctl(fd, DRM_IOCTL_I915_QUERY, &query);
	if (err) ...

	// We can now access each engine in the array
	for (i = 0; i < info->num_engines; i++) {
		struct drm_i915_engine_info einfo = info->engines[i];
		u16 class = einfo.engine.class;
		u16 instance = einfo.engine.instance;
		....
	}

	free(info);

Each of the enumerated engines, apart from being defined by its class and
instance (see `struct i915_engine_class_instance`), also can have flags and
capabilities defined as documented in i915_drm.h.

For instance video engines which support HEVC encoding will have the
`I915_VIDEO_CLASS_CAPABILITY_HEVC` capability bit set.

Engine discovery only fully comes to its own when combined with the new way of
addressing engines when submitting batch buffers using contexts with engine
maps configured.

Context Engine Map uAPI
-----------------------

Context engine map is a new way of addressing engines when submitting batch-
buffers, replacing the existing way of using identifiers like `I915_EXEC_BLT`
inside the flags field of `struct drm_i915_gem_execbuffer2`.

To use it created GEM contexts need to be configured with a list of engines
the user is intending to submit to. This is accomplished using the
`I915_CONTEXT_PARAM_ENGINES` parameter and `struct i915_context_param_engines`.

For such contexts the `I915_EXEC_RING_MASK` field becomes an index into the
configured map.

Example of creating such context and submitting against it:

.. code-block:: C

	I915_DEFINE_CONTEXT_PARAM_ENGINES(engines, 2) = {
		.engines = { { I915_ENGINE_CLASS_RENDER, 0 },
			     { I915_ENGINE_CLASS_COPY, 0 } }
	};
	struct drm_i915_gem_context_create_ext_setparam p_engines = {
		.base = {
			.name = I915_CONTEXT_CREATE_EXT_SETPARAM,
		},
		.param = {
			.param = I915_CONTEXT_PARAM_ENGINES,
			.value = to_user_pointer(&engines),
			.size = sizeof(engines),
		},
	};
	struct drm_i915_gem_context_create_ext create = {
		.flags = I915_CONTEXT_CREATE_FLAGS_USE_EXTENSIONS,
		.extensions = to_user_pointer(&p_engines);
	};

	ctx_id = gem_context_create_ext(drm_fd, &create);

	// We have now created a GEM context with two engines in the map:
	// Index 0 points to rcs0 while index 1 points to bcs0. Other engines
	// will not be accessible from this context.

	...
	execbuf.rsvd1 = ctx_id;
	execbuf.flags = 0; // Submits to index0, which is rcs0 for this context
	gem_execbuf(drm_fd, &execbuf);

	...
	execbuf.rsvd1 = ctx_id;
	execbuf.flags = 1; // Submits to index0, which is bcs0 for this context
	gem_execbuf(drm_fd, &execbuf);

Virtual Engine uAPI
-------------------

Virtual engine is a concept where userspace is able to configure a set of
physical engines, submit a batch buffer, and let the driver execute it on any
engine from the set as it sees fit.

This is primarily useful on parts which have multiple instances of a same class
engine, like for example GT3+ Skylake parts with their two VCS engines.

For instance userspace can enumerate all engines of a certain class using the
previously described `Engine Discovery uAPI`_. After
that userspace can create a GEM context with a placeholder slot for the virtual
engine (using `I915_ENGINE_CLASS_INVALID` and `I915_ENGINE_CLASS_INVALID_NONE`
for class and instance respectively) and finally using the
`I915_CONTEXT_ENGINES_EXT_LOAD_BALANCE` extension place a virtual engine in the
same reserved slot.

Example of creating a virtual engine and submitting a batch buffer to it:

.. code-block:: C

	I915_DEFINE_CONTEXT_ENGINES_LOAD_BALANCE(virtual, 2) = {
		.base.name = I915_CONTEXT_ENGINES_EXT_LOAD_BALANCE,
		.engine_index = 0, // Place this virtual engine into engine map slot 0
		.num_siblings = 2,
		.engines = { { I915_ENGINE_CLASS_VIDEO, 0 },
			     { I915_ENGINE_CLASS_VIDEO, 1 }, },
	};
	I915_DEFINE_CONTEXT_PARAM_ENGINES(engines, 1) = {
		.engines = { { I915_ENGINE_CLASS_INVALID,
			       I915_ENGINE_CLASS_INVALID_NONE } },
		.extensions = to_user_pointer(&virtual), // Chains with the load_balance extension
	};
	struct drm_i915_gem_context_create_ext_setparam p_engines = {
		.base = {
			.name = I915_CONTEXT_CREATE_EXT_SETPARAM,
		},
		.param = {
			.param = I915_CONTEXT_PARAM_ENGINES,
			.value = to_user_pointer(&engines),
			.size = sizeof(engines),
		},
	};
	struct drm_i915_gem_context_create_ext create = {
		.flags = I915_CONTEXT_CREATE_FLAGS_USE_EXTENSIONS,
		.extensions = to_user_pointer(&p_engines);
	};

	ctx_id = gem_context_create_ext(drm_fd, &create);

	// Now we have created a GEM context with its engine map containing a
	// single virtual engine. Submissions to this slot can go either to
	// vcs0 or vcs1, depending on the load balancing algorithm used inside
	// the driver. The load balancing is dynamic from one batch buffer to
	// another and transparent to userspace.

	...
	execbuf.rsvd1 = ctx_id;
	execbuf.flags = 0; // Submits to index0 which is the virtual engine
	gem_execbuf(drm_fd, &execbuf);

Locking Guidelines
------------------

.. note::
   This is a description of how the locking should be after
   refactoring is done. Does not necessarily reflect what the locking
   looks like while WIP.

#. All locking rules and interface contracts with cross-driver interfaces
   (dma-buf, dma_fence) need to be followed.

#. No struct_mutex anywhere in the code

#. dma_resv will be the outermost lock (when needed) and ww_acquire_ctx
   is to be hoisted at highest level and passed down within i915_gem_ctx
   in the call chain

#. While holding lru/memory manager (buddy, drm_mm, whatever) locks
   system memory allocations are not allowed

	* Enforce this by priming lockdep (with fs_reclaim). If we
	  allocate memory while holding these looks we get a rehash
	  of the shrinker vs. struct_mutex saga, and that would be
	  real bad.

#. Do not nest different lru/memory manager locks within each other.
   Take them in turn to update memory allocations, relying on the object’s
   dma_resv ww_mutex to serialize against other operations.

#. The suggestion for lru/memory managers locks is that they are small
   enough to be spinlocks.

#. All features need to come with exhaustive kernel selftests and/or
   IGT tests when appropriate

#. All LMEM uAPI paths need to be fully restartable (_interruptible()
   for all locks/waits/sleeps)

	* Error handling validation through signal injection.
	  Still the best strategy we have for validating GEM uAPI
          corner cases.
	  Must be excessively used in the IGT, and we need to check
	  that we really have full path coverage of all error cases.

	* -EDEADLK handling with ww_mutex

GEM BO Management Implementation Details
----------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_vma_types.h
   :doc: Virtual Memory Address

Buffer Object Eviction
----------------------

This section documents the interface functions for evicting buffer
objects to make space available in the virtual gpu address spaces. Note
that this is mostly orthogonal to shrinking buffer objects caches, which
has the goal to make main memory (shared with the gpu through the
unified memory architecture) available.

.. kernel-doc:: drivers/gpu/drm/i915/i915_gem_evict.c
   :internal:

Buffer Object Memory Shrinking
------------------------------

This section documents the interface function for shrinking memory usage
of buffer object caches. Shrinking is used to make main memory
available. Note that this is mostly orthogonal to evicting buffer
objects, which has the goal to make space in gpu virtual address spaces.

.. kernel-doc:: drivers/gpu/drm/i915/gem/i915_gem_shrinker.c
   :internal:

Batchbuffer Parsing
-------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_cmd_parser.c
   :doc: batch buffer command parser

.. kernel-doc:: drivers/gpu/drm/i915/i915_cmd_parser.c
   :internal:

User Batchbuffer Execution
--------------------------

.. kernel-doc:: drivers/gpu/drm/i915/gem/i915_gem_execbuffer.c
   :doc: User command execution

Logical Rings, Logical Ring Contexts and Execlists
--------------------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/gt/intel_execlists_submission.c
   :doc: Logical Rings, Logical Ring Contexts and Execlists

Global GTT views
----------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_vma_types.h
   :doc: Global GTT views

.. kernel-doc:: drivers/gpu/drm/i915/i915_gem_gtt.c
   :internal:

GTT Fences and Swizzling
------------------------

.. kernel-doc:: drivers/gpu/drm/i915/gt/intel_ggtt_fencing.c
   :internal:

Global GTT Fence Handling
~~~~~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/intel_ggtt_fencing.c
   :doc: fence register handling

Hardware Tiling and Swizzling Details
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/intel_ggtt_fencing.c
   :doc: tiling swizzling details

Object Tiling IOCTLs
--------------------

.. kernel-doc:: drivers/gpu/drm/i915/gem/i915_gem_tiling.c
   :internal:

.. kernel-doc:: drivers/gpu/drm/i915/gem/i915_gem_tiling.c
   :doc: buffer object tiling

Microcontrollers
================

Starting from gen9, three microcontrollers are available on the HW: the
graphics microcontroller (GuC), the HEVC/H.265 microcontroller (HuC) and the
display microcontroller (DMC). The driver is responsible for loading the
firmwares on the microcontrollers; the GuC and HuC firmwares are transferred
to WOPCM using the DMA engine, while the DMC firmware is written through MMIO.

WOPCM
-----

WOPCM Layout
~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/intel_wopcm.c
   :doc: WOPCM Layout

GuC
---

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_guc.c
   :doc: GuC

GuC Firmware Layout
~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_uc_fw_abi.h
   :doc: Firmware Layout

GuC Memory Management
~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_guc.c
   :doc: GuC Memory Management
.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_guc.c
   :functions: intel_guc_allocate_vma


GuC-specific firmware loader
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_guc_fw.c
   :internal:

GuC-based command submission
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_guc_submission.c
   :doc: GuC-based command submission

HuC
---
.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_huc.c
   :doc: HuC
.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_huc.c
   :functions: intel_huc_auth

HuC Memory Management
~~~~~~~~~~~~~~~~~~~~~

.. kernel-doc:: drivers/gpu/drm/i915/gt/uc/intel_huc.c
   :doc: HuC Memory Management

HuC Firmware Layout
~~~~~~~~~~~~~~~~~~~
The HuC FW layout is the same as the GuC one, see `GuC Firmware Layout`_

DMC
---
See `DMC Firmware Support`_

Tracing
=======

This sections covers all things related to the tracepoints implemented
in the i915 driver.

i915_ppgtt_create and i915_ppgtt_release
----------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_trace.h
   :doc: i915_ppgtt_create and i915_ppgtt_release tracepoints

i915_context_create and i915_context_free
-----------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_trace.h
   :doc: i915_context_create and i915_context_free tracepoints

Perf
====

Overview
--------
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :doc: i915 Perf Overview

Comparison with Core Perf
-------------------------
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :doc: i915 Perf History and Comparison with Core Perf

i915 Driver Entry Points
------------------------

This section covers the entrypoints exported outside of i915_perf.c to
integrate with drm/i915 and to handle the `DRM_I915_PERF_OPEN` ioctl.

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_init
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_fini
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_register
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_unregister
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_open_ioctl
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_release
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_add_config_ioctl
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_remove_config_ioctl

i915 Perf Stream
----------------

This section covers the stream-semantics-agnostic structures and functions
for representing an i915 perf stream FD and associated file operations.

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf_types.h
   :functions: i915_perf_stream
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf_types.h
   :functions: i915_perf_stream_ops

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: read_properties_unlocked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_open_ioctl_locked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_destroy_locked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_read
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_ioctl
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_enable_locked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_disable_locked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_poll
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_perf_poll_locked

i915 Perf Observation Architecture Stream
-----------------------------------------

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf_types.h
   :functions: i915_oa_ops

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_stream_init
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_read
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_stream_enable
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_stream_disable
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_wait_unlocked
.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :functions: i915_oa_poll_wait

Other i915 Perf Internals
-------------------------

This section simply includes all other currently documented i915 perf internals,
in no particular order, but may include some more minor utilities or platform
specific details than found in the more high-level sections.

.. kernel-doc:: drivers/gpu/drm/i915/i915_perf.c
   :internal:
   :no-identifiers:
       i915_perf_init
       i915_perf_fini
       i915_perf_register
       i915_perf_unregister
       i915_perf_open_ioctl
       i915_perf_release
       i915_perf_add_config_ioctl
       i915_perf_remove_config_ioctl
       read_properties_unlocked
       i915_perf_open_ioctl_locked
       i915_perf_destroy_locked
       i915_perf_read i915_perf_ioctl
       i915_perf_enable_locked
       i915_perf_disable_locked
       i915_perf_poll i915_perf_poll_locked
       i915_oa_stream_init i915_oa_read
       i915_oa_stream_enable
       i915_oa_stream_disable
       i915_oa_wait_unlocked
       i915_oa_poll_wait

Style
=====

The drm/i915 driver codebase has some style rules in addition to (and, in some
cases, deviating from) the kernel coding style.

Register macro definition style
-------------------------------

The style guide for ``i915_reg.h``.

.. kernel-doc:: drivers/gpu/drm/i915/i915_reg.h
   :doc: The i915 register macro definition style guide
